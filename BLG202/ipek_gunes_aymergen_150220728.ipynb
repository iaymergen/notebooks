{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "\n",
    "df = pd.read_csv('comcast_consumeraffairs_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>Nov. 22, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love Comcast. Until all these consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>Nov. 19, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm so over Comcast! The worst internet provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>Nov. 17, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give them a negative star or no sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>Nov. 16, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had the worst experiences so far since in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>Nov. 14, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Check your contract when you sign up for Comca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author      posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI  Nov. 22, 2016       1   \n",
       "1     Vera of Philadelphia, PA  Nov. 19, 2016       1   \n",
       "2  Sarah of Rancho Cordova, CA  Nov. 17, 2016       1   \n",
       "3     Dennis of Manchester, NH  Nov. 16, 2016       1   \n",
       "4         Ryan of Bellevue, WA  Nov. 14, 2016       1   \n",
       "\n",
       "                                                text  \n",
       "0  I used to love Comcast. Until all these consta...  \n",
       "1  I'm so over Comcast! The worst internet provid...  \n",
       "2  If I could give them a negative star or no sta...  \n",
       "3  I've had the worst experiences so far since in...  \n",
       "4  Check your contract when you sign up for Comca...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset's general info\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5659 entries, 0 to 5658\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   author     5659 non-null   object\n",
      " 1   posted_on  5659 non-null   object\n",
      " 2   rating     5659 non-null   int64 \n",
      " 3   text       5629 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 177.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5659.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.822053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.669991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating\n",
       "count  5659.000000\n",
       "mean      0.822053\n",
       "std       0.669991\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author        0\n",
       "posted_on     0\n",
       "rating        0\n",
       "text         30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is missing data\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ipek\\AppData\\Local\\Temp\\ipykernel_70084\\1203380223.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['posted_on'] = pd.to_datetime(df['posted_on'], errors='coerce', infer_datetime_format=True) #convert to datetime\n"
     ]
    }
   ],
   "source": [
    "df['posted_on'] = pd.to_datetime(df['posted_on'], errors='coerce', infer_datetime_format=True) #convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the rows with missing data \n",
    "\n",
    "df = df.dropna(subset=['posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the complaints prior to 2009\n",
    "\n",
    "df = df[df['posted_on'].dt.year >= 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author       0\n",
       "posted_on    0\n",
       "rating       0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset after the process\n",
    "\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2607 entries, 0 to 5200\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   author     2607 non-null   object        \n",
      " 1   posted_on  2607 non-null   datetime64[ns]\n",
      " 2   rating     2607 non-null   int64         \n",
      " 3   text       2607 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 101.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text using NLTK's word_tokenize() function\n",
    "df['tokenized_text'] = df['text'].apply(word_tokenize) # Apply it to all rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [I, used, to, love, Comcast, ., Until, all, th...\n",
      "1    [I, 'm, so, over, Comcast, !, The, worst, inte...\n",
      "2    [If, I, could, give, them, a, negative, star, ...\n",
      "3    [I, 've, had, the, worst, experiences, so, far...\n",
      "4    [Check, your, contract, when, you, sign, up, f...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the tokenization\n",
    "print(df['tokenized_text'].head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love Comcast. Until all these consta...</td>\n",
       "      <td>[I, used, to, love, Comcast, ., Until, all, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm so over Comcast! The worst internet provid...</td>\n",
       "      <td>[I, 'm, so, over, Comcast, !, The, worst, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give them a negative star or no sta...</td>\n",
       "      <td>[If, I, could, give, them, a, negative, star, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had the worst experiences so far since in...</td>\n",
       "      <td>[I, 've, had, the, worst, experiences, so, far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Check your contract when you sign up for Comca...</td>\n",
       "      <td>[Check, your, contract, when, you, sign, up, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI 2016-11-22       1   \n",
       "1     Vera of Philadelphia, PA 2016-11-19       1   \n",
       "2  Sarah of Rancho Cordova, CA 2016-11-17       1   \n",
       "3     Dennis of Manchester, NH 2016-11-16       1   \n",
       "4         Ryan of Bellevue, WA 2016-11-14       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  I used to love Comcast. Until all these consta...   \n",
       "1  I'm so over Comcast! The worst internet provid...   \n",
       "2  If I could give them a negative star or no sta...   \n",
       "3  I've had the worst experiences so far since in...   \n",
       "4  Check your contract when you sign up for Comca...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [I, used, to, love, Comcast, ., Until, all, th...  \n",
       "1  [I, 'm, so, over, Comcast, !, The, worst, inte...  \n",
       "2  [If, I, could, give, them, a, negative, star, ...  \n",
       "3  [I, 've, had, the, worst, experiences, so, far...  \n",
       "4  [Check, your, contract, when, you, sign, up, f...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Now we have an additional column but we'll delete it afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords function\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token.lower() not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from the 'tokenized_text' column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(remove_stopwords) # Apply to all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [used, love, Comcast, ., constant, updates, .,...\n",
      "1    ['m, Comcast, !, worst, internet, provider, .,...\n",
      "2    [could, give, negative, star, stars, review, w...\n",
      "3    ['ve, worst, experiences, far, since, install,...\n",
      "4    [Check, contract, sign, Comcast, advertised, o...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the removal of stopwords\n",
    "print(df['tokenized_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love Comcast. Until all these consta...</td>\n",
       "      <td>[used, love, Comcast, ., constant, updates, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm so over Comcast! The worst internet provid...</td>\n",
       "      <td>['m, Comcast, !, worst, internet, provider, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give them a negative star or no sta...</td>\n",
       "      <td>[could, give, negative, star, stars, review, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had the worst experiences so far since in...</td>\n",
       "      <td>['ve, worst, experiences, far, since, install,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Check your contract when you sign up for Comca...</td>\n",
       "      <td>[Check, contract, sign, Comcast, advertised, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI 2016-11-22       1   \n",
       "1     Vera of Philadelphia, PA 2016-11-19       1   \n",
       "2  Sarah of Rancho Cordova, CA 2016-11-17       1   \n",
       "3     Dennis of Manchester, NH 2016-11-16       1   \n",
       "4         Ryan of Bellevue, WA 2016-11-14       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  I used to love Comcast. Until all these consta...   \n",
       "1  I'm so over Comcast! The worst internet provid...   \n",
       "2  If I could give them a negative star or no sta...   \n",
       "3  I've had the worst experiences so far since in...   \n",
       "4  Check your contract when you sign up for Comca...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [used, love, Comcast, ., constant, updates, .,...  \n",
       "1  ['m, Comcast, !, worst, internet, provider, .,...  \n",
       "2  [could, give, negative, star, stars, review, w...  \n",
       "3  ['ve, worst, experiences, far, since, install,...  \n",
       "4  [Check, contract, sign, Comcast, advertised, o...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming function\n",
    "def perform_stemming(tokens):\n",
    "    return [porter_stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stemming on the 'tokenized_text' column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(perform_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [use, love, comcast, ., constant, updat, ., in...\n",
      "1    ['m, comcast, !, worst, internet, provid, ., '...\n",
      "2    [could, give, neg, star, star, review, would, ...\n",
      "3    ['ve, worst, experi, far, sinc, instal, 10/4/1...\n",
      "4    [check, contract, sign, comcast, advertis, off...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the stemming\n",
    "print(df['tokenized_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love Comcast. Until all these consta...</td>\n",
       "      <td>[use, love, comcast, ., constant, updat, ., in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm so over Comcast! The worst internet provid...</td>\n",
       "      <td>['m, comcast, !, worst, internet, provid, ., '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give them a negative star or no sta...</td>\n",
       "      <td>[could, give, neg, star, star, review, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had the worst experiences so far since in...</td>\n",
       "      <td>['ve, worst, experi, far, sinc, instal, 10/4/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Check your contract when you sign up for Comca...</td>\n",
       "      <td>[check, contract, sign, comcast, advertis, off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI 2016-11-22       1   \n",
       "1     Vera of Philadelphia, PA 2016-11-19       1   \n",
       "2  Sarah of Rancho Cordova, CA 2016-11-17       1   \n",
       "3     Dennis of Manchester, NH 2016-11-16       1   \n",
       "4         Ryan of Bellevue, WA 2016-11-14       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  I used to love Comcast. Until all these consta...   \n",
       "1  I'm so over Comcast! The worst internet provid...   \n",
       "2  If I could give them a negative star or no sta...   \n",
       "3  I've had the worst experiences so far since in...   \n",
       "4  Check your contract when you sign up for Comca...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [use, love, comcast, ., constant, updat, ., in...  \n",
       "1  ['m, comcast, !, worst, internet, provid, ., '...  \n",
       "2  [could, give, neg, star, star, review, would, ...  \n",
       "3  ['ve, worst, experi, far, sinc, instal, 10/4/1...  \n",
       "4  [check, contract, sign, comcast, advertis, off...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization function\n",
    "def perform_lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform lemmatization on the 'tokenized_text' column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [use, love, comcast, ., constant, updat, ., in...\n",
      "1    ['m, comcast, !, worst, internet, provid, ., '...\n",
      "2    [could, give, neg, star, star, review, would, ...\n",
      "3    ['ve, worst, experi, far, sinc, instal, 10/4/1...\n",
      "4    [check, contract, sign, comcast, advertis, off...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the lemmatization\n",
    "print(df['tokenized_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love Comcast. Until all these consta...</td>\n",
       "      <td>[use, love, comcast, ., constant, updat, ., in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm so over Comcast! The worst internet provid...</td>\n",
       "      <td>['m, comcast, !, worst, internet, provid, ., '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give them a negative star or no sta...</td>\n",
       "      <td>[could, give, neg, star, star, review, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had the worst experiences so far since in...</td>\n",
       "      <td>['ve, worst, experi, far, sinc, instal, 10/4/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Check your contract when you sign up for Comca...</td>\n",
       "      <td>[check, contract, sign, comcast, advertis, off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI 2016-11-22       1   \n",
       "1     Vera of Philadelphia, PA 2016-11-19       1   \n",
       "2  Sarah of Rancho Cordova, CA 2016-11-17       1   \n",
       "3     Dennis of Manchester, NH 2016-11-16       1   \n",
       "4         Ryan of Bellevue, WA 2016-11-14       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  I used to love Comcast. Until all these consta...   \n",
       "1  I'm so over Comcast! The worst internet provid...   \n",
       "2  If I could give them a negative star or no sta...   \n",
       "3  I've had the worst experiences so far since in...   \n",
       "4  Check your contract when you sign up for Comca...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [use, love, comcast, ., constant, updat, ., in...  \n",
       "1  ['m, comcast, !, worst, internet, provid, ., '...  \n",
       "2  [could, give, neg, star, star, review, would, ...  \n",
       "3  ['ve, worst, experi, far, sinc, instal, 10/4/1...  \n",
       "4  [check, contract, sign, comcast, advertis, off...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'text' column with the preprocessed tokenized text\n",
    "df['text'] = df['tokenized_text'].apply(lambda x: ' '.join(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the 'tokenized_text' column\n",
    "df.drop(columns=['tokenized_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_on</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alantae of Chesterfeild, MI</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>use love comcast . constant updat . internet c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera of Philadelphia, PA</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>'m comcast ! worst internet provid . 'm take o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah of Rancho Cordova, CA</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>could give neg star star review would . never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis of Manchester, NH</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1</td>\n",
       "      <td>'ve worst experi far sinc instal 10/4/16 . not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan of Bellevue, WA</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1</td>\n",
       "      <td>check contract sign comcast advertis offer mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  posted_on  rating  \\\n",
       "0  Alantae of Chesterfeild, MI 2016-11-22       1   \n",
       "1     Vera of Philadelphia, PA 2016-11-19       1   \n",
       "2  Sarah of Rancho Cordova, CA 2016-11-17       1   \n",
       "3     Dennis of Manchester, NH 2016-11-16       1   \n",
       "4         Ryan of Bellevue, WA 2016-11-14       1   \n",
       "\n",
       "                                                text  \n",
       "0  use love comcast . constant updat . internet c...  \n",
       "1  'm comcast ! worst internet provid . 'm take o...  \n",
       "2  could give neg star star review would . never ...  \n",
       "3  've worst experi far sinc instal 10/4/16 . not...  \n",
       "4  check contract sign comcast advertis offer mat...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Now we don't have the extra column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the 'text' column to create the term-by-document matrix\n",
    "term_document_matrix = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the term-document matrix to an array\n",
    "term_document_matrix_array = term_document_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of term-document matrix: (2607, 7934)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape\n",
    "print(\"Shape of term-document matrix:\", term_document_matrix_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the matrix\n",
    "normalized_term_document_matrix = term_document_matrix_array / np.linalg.norm(term_document_matrix_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized term-document matrix: (2607, 7934)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape\n",
    "print(\"Shape of normalized term-document matrix:\", normalized_term_document_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix U:\n",
      "[[-3.08107501e-03  2.38490206e-03 -3.29628042e-03 ...  6.56072337e-05\n",
      "  -1.58178300e-03 -1.00796317e-17]\n",
      " [-4.34116050e-03  8.42357239e-03 -1.03542179e-02 ... -1.60692204e-03\n",
      "   1.11890415e-02  1.12438213e-16]\n",
      " [-1.44585222e-02  2.54317331e-02 -1.48559889e-02 ... -1.20902347e-03\n",
      "   4.06331859e-04 -9.48542281e-17]\n",
      " ...\n",
      " [-6.88218660e-03  6.56142495e-03  1.24844916e-03 ...  1.50044777e-02\n",
      "   8.61013219e-03 -1.77180452e-16]\n",
      " [-4.92560748e-03  9.15698747e-03  1.13520531e-02 ... -6.42198676e-03\n",
      "  -1.98228210e-03 -1.57132766e-16]\n",
      " [-5.37214286e-03  1.15579034e-02 -1.07828141e-02 ... -5.26436931e-04\n",
      "  -7.08056084e-04  5.08037447e-17]]\n",
      "Matrix Sigma:\n",
      "[5.47667485e-01 1.72734912e-01 1.44852707e-01 ... 2.81546202e-04\n",
      " 2.19187675e-04 2.83689612e-18]\n",
      "Matrix VT:\n",
      "[[-3.59234471e-02 -7.99469065e-04 -6.84921791e-04 ... -1.25599876e-05\n",
      "  -1.22440829e-04 -1.48536295e-04]\n",
      " [ 3.82596622e-02  2.93602778e-03  1.14416994e-04 ... -3.21962556e-05\n",
      "   1.62824589e-04 -1.32576877e-04]\n",
      " [ 4.64851584e-02 -1.39634983e-03 -2.26160719e-03 ...  4.58567330e-05\n",
      "  -2.25747654e-05 -2.26375776e-04]\n",
      " ...\n",
      " [-1.80740112e-04 -4.44826432e-03  2.33583038e-03 ...  8.66818641e-01\n",
      "  -4.58925717e-03  2.08787206e-03]\n",
      " [-6.48939971e-05 -5.03277440e-03  5.45257072e-04 ... -4.48074683e-03\n",
      "   7.09726377e-01 -5.02390080e-03]\n",
      " [ 4.49322603e-04  5.94378756e-05 -4.73873928e-03 ...  2.05901052e-04\n",
      "  -6.84374670e-03  9.29991178e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    def center_data(matrix): # centering data function\\n    mean = np.mean(matrix, axis=0)\\n    centered_matrix = matrix - mean\\n    return centered_matrix, mean\\n\\ndef power_iteration(A, num_iterations):\\n    n = A.shape[0]\\n    v = np.random.rand(n)  # Random initialization of eigenvector\\n    for _ in range(num_iterations): # range according to the input parameter\\n        v = A @ v\\n        v /= np.linalg.norm(v)  # Normalize the vector\\n    eigenvalue = np.dot(A @ v, v) / np.dot(v, v)  # Rayleigh quotient approximation\\n    return eigenvalue, v\\n\\n\\ndef svd(matrix, num_iterations=10): # SVD function using the above functions\\n    # Center the data\\n    centered_matrix, mean = center_data(matrix)\\n\\n    # Compute the Covariance Matrix\\n    covariance_matrix = np.cov(centered_matrix, rowvar=False)\\n\\n    # Power Iteration\\n    eigenvalues = [] # define the esgenvalues and eigenvectors\\n    eigenvectors = []\\n    for _ in range(matrix.shape[1]):\\n        eigenvalue, eigenvector = power_iteration(covariance_matrix, num_iterations)\\n        eigenvalues.append(eigenvalue)\\n        eigenvectors.append(eigenvector)\\n\\n        covariance_matrix -= eigenvalue * np.outer(eigenvector, eigenvector)\\n\\n    # Create Matrix U and Sigma\\n    U = np.array(eigenvectors).T\\n    Sigma = np.diag(np.sqrt(eigenvalues))\\n\\n    # Compute Matrix V\\n    V = np.dot(centered_matrix.T, U) / np.diag(Sigma)\\n\\n    return U, Sigma, V # return the values\\n\\n\\n# Perform Singular Value Decomposition\\nU, Sigma, VT = svd(normalized_term_document_matrix)\\n\\n\\n'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform SVD\n",
    "U, Sigma, VT = np.linalg.svd(normalized_term_document_matrix)\n",
    "\n",
    "# Print the matrices U, Sigma, and VT\n",
    "print(\"Matrix U:\")\n",
    "print(U)\n",
    "print(\"Matrix Sigma:\")\n",
    "print(Sigma)\n",
    "print(\"Matrix VT:\")\n",
    "print(VT)\n",
    "\n",
    "\n",
    "\n",
    "# I tried to do this but it's not functioning properly so to continue the next steps i used built in libarary but i added it in the following comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def center_data(matrix):\\n    mean = np.mean(matrix, axis=0)\\n    centered_matrix = matrix - mean\\n    return centered_matrix, mean\\n\\ndef power_iteration(A, num_iterations):\\n    n = A.shape[0]\\n    v = np.random.rand(n)  # Random initialization of eigenvector\\n    for _ in range(num_iterations):\\n        v = A @ v\\n        v /= np.linalg.norm(v)  # Normalize the vector\\n    eigenvalue = np.dot(A @ v, v) / np.dot(v, v)  # Rayleigh quotient approximation\\n    return eigenvalue, v'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def center_data(matrix): # centering data function\n",
    "    mean = np.mean(matrix, axis=0)\n",
    "    centered_matrix = matrix - mean\n",
    "    return centered_matrix, mean\n",
    "\n",
    "def power_iteration(A, num_iterations):\n",
    "    n = A.shape[0]\n",
    "    v = np.random.rand(n)  # Random initialization of eigenvector\n",
    "    for _ in range(num_iterations): # range according to the input parameter\n",
    "        v = A @ v\n",
    "        v /= np.linalg.norm(v)  # Normalize the vector\n",
    "    eigenvalue = np.dot(A @ v, v) / np.dot(v, v)  # Rayleigh quotient approximation\n",
    "    return eigenvalue, v\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def svd(matrix, num_iterations=10):\\n    # Step 1: Center the data\\n    centered_matrix, mean = center_data(matrix)\\n\\n    # Step 2: Compute the Covariance Matrix\\n    covariance_matrix = np.cov(centered_matrix, rowvar=False)\\n\\n    # Step 3: Power Iteration for Principal Component\\n    eigenvalues = []\\n    eigenvectors = []\\n    for _ in range(matrix.shape[1]):\\n        eigenvalue, eigenvector = power_iteration(covariance_matrix, num_iterations)\\n        eigenvalues.append(eigenvalue)\\n        eigenvectors.append(eigenvector)\\n\\n        # Deflation\\n        covariance_matrix -= eigenvalue * np.outer(eigenvector, eigenvector)\\n\\n    # Step 4: Construct Matrix U and Sigma\\n    U = np.array(eigenvectors).T\\n    Sigma = np.diag(np.sqrt(eigenvalues))\\n\\n    # Step 5: Compute Matrix V\\n    V = np.dot(centered_matrix.T, U) / np.diag(Sigma)\\n\\n    return U, Sigma, V'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def svd(matrix, num_iterations=10): # SVD function using the above functions\n",
    "    # Center the data\n",
    "    centered_matrix, mean = center_data(matrix)\n",
    "\n",
    "    # Compute the Covariance Matrix\n",
    "    covariance_matrix = np.cov(centered_matrix, rowvar=False)\n",
    "\n",
    "    # Power Iteration\n",
    "    eigenvalues = [] # define the esgenvalues and eigenvectors\n",
    "    eigenvectors = []\n",
    "    for _ in range(matrix.shape[1]):\n",
    "        eigenvalue, eigenvector = power_iteration(covariance_matrix, num_iterations)\n",
    "        eigenvalues.append(eigenvalue)\n",
    "        eigenvectors.append(eigenvector)\n",
    "\n",
    "        covariance_matrix -= eigenvalue * np.outer(eigenvector, eigenvector)\n",
    "\n",
    "    # Create Matrix U and Sigma\n",
    "    U = np.array(eigenvectors).T\n",
    "    Sigma = np.diag(np.sqrt(eigenvalues))\n",
    "\n",
    "    # Compute Matrix V\n",
    "    V = np.dot(centered_matrix.T, U) / np.diag(Sigma)\n",
    "\n",
    "    return U, Sigma, V # return the values\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Perform Singular Value Decomposition\\nU, Sigma, VT = svd(normalized_term_document_matrix)\\n'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Perform Singular Value Decomposition\n",
    "U, Sigma, VT = svd(normalized_term_document_matrix)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U matrix: (2607, 2607)\n",
      "Shape of Sigma matrix: (2607,)\n",
      "Shape of VT matrix: (7934, 7934)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of U, Sigma, and VT matrices\n",
    "print(\"Shape of U matrix:\", U.shape)\n",
    "print(\"Shape of Sigma matrix:\", Sigma.shape)\n",
    "print(\"Shape of VT matrix:\", VT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range\n",
    "k_values = range(10, min(normalized_term_document_matrix.shape) // 10 + 1, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variabless for storing k's\n",
    "mse_errors = []\n",
    "fn_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction errors for ks\n",
    "for k in k_values:\n",
    "    # Approximate the original matrix\n",
    "    reconstructed_matrix = U[:, :k] @ np.diag(Sigma[:k]) @ VT[:k, :]\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    mse = np.mean((normalized_term_document_matrix - reconstructed_matrix) ** 2)\n",
    "    mse_errors.append(mse)\n",
    "    \n",
    "    # Calculate Frobenius Norm\n",
    "    fn = np.linalg.norm(normalized_term_document_matrix - reconstructed_matrix)\n",
    "    fn_errors.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the minimum MSE and FN\n",
    "min_mse_index = np.argmin(mse_errors)\n",
    "min_fn_index = np.argmin(fn_errors)\n",
    "\n",
    "# Optimal k based on least MSE and FN errors\n",
    "optimal_k_mse = k_values[min_mse_index]\n",
    "optimal_k_fn = k_values[min_fn_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k based on least MSE: 250\n",
      "Optimal k based on least FN: 250\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal k based on least MSE:\", optimal_k_mse)\n",
    "print(\"Optimal k based on least FN:\", optimal_k_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Reconstruction Error: 6.857711594030514e-09\n",
      "FN Reconstruction Error: 0.37662246538517613\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the original matrix\n",
    "reconstructed_matrix = U[:, :optimal_k_mse] @ np.diag(Sigma[:optimal_k_mse]) @ VT[:optimal_k_mse, :]\n",
    "\n",
    "# Calculate the reconstruction error\n",
    "mse_reconstruction_error = np.mean((normalized_term_document_matrix - reconstructed_matrix) ** 2)\n",
    "fn_reconstruction_error = np.linalg.norm(normalized_term_document_matrix - reconstructed_matrix)\n",
    "\n",
    "print(\"MSE Reconstruction Error:\", mse_reconstruction_error)\n",
    "print(\"FN Reconstruction Error:\", fn_reconstruction_error)\n",
    "\n",
    "# the errors are pretty small so it is good \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 250 # assume our k accoring to the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query vectors from the question\n",
    "queries = {\n",
    "    'query1': ['ignorant', 'overwhelming'],\n",
    "    'query2': ['xfinity', 'frustrate', 'adapter', 'verizon', 'router'],\n",
    "    'query3': ['terminate', 'rent', 'promotion', 'joke', 'liar', 'internet', 'horrible'],\n",
    "    'query4': ['kindergarten', 'ridiculous', 'internet', 'clerk', 'terrible']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Converting queries into query vectors\n",
    "query_vectors = {}\n",
    "for query_name, query_terms in queries.items():\n",
    "    query_vector = np.zeros(len(vectorizer.vocabulary_), dtype=int)\n",
    "    for term in query_terms:\n",
    "        if term in vectorizer.vocabulary_:\n",
    "            query_vector[vectorizer.vocabulary_[term]] = 1\n",
    "    query_vectors[query_name] = query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ipek\\AppData\\Local\\Temp\\ipykernel_70084\\2235220125.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  cosine_similarities[query_name] = np.dot(query_vector, normalized_term_document_matrix.T) / (\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity\n",
    "cosine_similarities = {}\n",
    "for query_name, query_vector in query_vectors.items():\n",
    "    cosine_similarities[query_name] = np.dot(query_vector, normalized_term_document_matrix.T) / (\n",
    "            np.linalg.norm(query_vector) * np.linalg.norm(normalized_term_document_matrix, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most relevant document for each query\n",
    "most_relevant_documents = {}\n",
    "for query_name, similarity_scores in cosine_similarities.items():\n",
    "    most_relevant_document_index = np.argmax(similarity_scores)\n",
    "    most_relevant_documents[query_name] = df.iloc[most_relevant_document_index]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant document for query1:\n",
      "use love comcast . constant updat . internet cabl crash lot night , sometim day , channel n't even work demand sometim n't play either . wish someth . min ago , internet crash 20 min reason . 'm tire think switch wow someth . plea get xfiniti .\n",
      "***-----------------------------------------------------------------------------------------***\n",
      "Most relevant document for query2:\n",
      "cancel account novemb . bring back equip , told order router septemb need return . state n't order receiv . said evid receiv up ( without signatur ) . say router never activ . iron , purchas router issu month earlier never offer free router . speak yolanda * * , account manag comcast , said worri ask receipt router purchas agre reimburs $ 139 last month plu extra $ 50 router receiv check within 4-6 weeks.aft wait 7 without check , call told need file claim up lost router would send check . one comcast said need call up 12/27 told comcast 's respons contact up , mine . n't feel comcast get keep money router never order go given cost . equip , would give back . evid sign activ want refund !\n",
      "***-----------------------------------------------------------------------------------------***\n",
      "Most relevant document for query3:\n",
      "'re ever plan get comcast internet provid , n't . cheat price packag expens horribl . make fals advertis claim fastest internet provid . 're . imagin pay $ 60 month averag internet work thing , seem like internet fluctuat like crazi slow 1 gb phone internet servic . go custom support ? call n't work 'll call 'll tell darn thing everi time solut internet -- `` restart modem . '' , n't work . tri negoti possibl fix issu , yet curv direct tri show packag make pay even even horribl servic . like go help ? go curv distract cheat make pay request ? comcast take step even creat xfiniti wifi modem without consent . start set-up , creat internet leav open . peopl use internet without pay singl bill , 're pay heavi load . honestli 're new tech well let explain fals market compani bullshit compani . first modem , internet box . insid made 90 . 're modern stuff . put 90 insid new plastic case say 're state art modem . pay le provid internet box n't even work well either way , fact make pay rent modem , full bull crap . like call would n't help . even go far disrespect hang call midway without even answer question . compani ca n't provid internet life , yet still fals advertis . suggest look differ internet servic comcast . better save lot money good internet stand , pay whole lot get internet slow sloth .\n",
      "***-----------------------------------------------------------------------------------------***\n",
      "Most relevant document for query4:\n",
      "'re ever plan get comcast internet provid , n't . cheat price packag expens horribl . make fals advertis claim fastest internet provid . 're . imagin pay $ 60 month averag internet work thing , seem like internet fluctuat like crazi slow 1 gb phone internet servic . go custom support ? call n't work 'll call 'll tell darn thing everi time solut internet -- `` restart modem . '' , n't work . tri negoti possibl fix issu , yet curv direct tri show packag make pay even even horribl servic . like go help ? go curv distract cheat make pay request ? comcast take step even creat xfiniti wifi modem without consent . start set-up , creat internet leav open . peopl use internet without pay singl bill , 're pay heavi load . honestli 're new tech well let explain fals market compani bullshit compani . first modem , internet box . insid made 90 . 're modern stuff . put 90 insid new plastic case say 're state art modem . pay le provid internet box n't even work well either way , fact make pay rent modem , full bull crap . like call would n't help . even go far disrespect hang call midway without even answer question . compani ca n't provid internet life , yet still fals advertis . suggest look differ internet servic comcast . better save lot money good internet stand , pay whole lot get internet slow sloth .\n",
      "***-----------------------------------------------------------------------------------------***\n"
     ]
    }
   ],
   "source": [
    "# Print the most relevant document for each query\n",
    "for query_name, document_text in most_relevant_documents.items():\n",
    "    print(f\"Most relevant document for {query_name}:\")\n",
    "    print(document_text)\n",
    "    print(\"***-----------------------------------------------------------------------------------------***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
